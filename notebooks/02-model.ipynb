{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981f4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd79a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",       \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=1, \n",
    "    activation='sigmoid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "27567a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inf > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6a06b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b5f5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "38b2828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class ValidDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, data):\n",
    "        self.path = path\n",
    "        data = data.reset_index(drop=True)\n",
    "        self.image = data['image'].tolist()\n",
    "        self.label = data['image'].map(lambda x : x.replace(\".jpg\",\".png\")).tolist()\n",
    "        transform = []\n",
    "        transform.append(A.RandomCrop(width=720, height=720))\n",
    "        transform.append(A.HorizontalFlip(p=0.5))\n",
    "        transform.append(A.PadIfNeeded(min_height=736, min_width=736, value=255))\n",
    "        self.transform = A.Compose(transform)\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "\n",
    "    def __image__(self, index):  \n",
    "        image = self.path + '/images/valid/' + self.image[index]\n",
    "        label = self.path + '/labels/valid/' + self.label[index]\n",
    "        image = cv2.imread(image)\n",
    "        label = cv2.imread(label)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        output = self.transform(image=image, mask=label)\n",
    "        image, label = output['image'], output['mask']\n",
    "        mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "        transform = []\n",
    "        transform.append(transforms.ToTensor())\n",
    "        transform.append(transforms.Normalize(mean, std))\n",
    "        transform = transforms.Compose(transform)\n",
    "        image = transform(image)\n",
    "        label = label.min(axis=-1)\n",
    "        label = (np.array(label) != 255).astype(float)\n",
    "        label = torch.from_numpy(label).squeeze()\n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.__image__(idx)\n",
    "        sample = {'idx': self.image[idx].replace(\".jpg\",\"\"), 'image': image, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23468865",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b953fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ValidDataset('../../data/', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e80714ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0adc9cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1.], dtype=torch.float64), tensor([537742,   3954]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['label'].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5ccd8e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 736, 736])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c448e837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0., dtype=torch.float64), tensor(1., dtype=torch.float64))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['label'].min(), a['label'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be217273",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data['image'].map(lambda x : x.replace(\".jpg\",\".png\")).tolist()\n",
    "images = ['../../data/labels/train/' + x for x in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92ab6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(cv2.imread(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c9d9aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        params = {}\n",
    "        params['encoder_name'] = 'resnet34'\n",
    "        params['encoder_weights'] = 'imagenet'\n",
    "        params['in_channels'] = 3\n",
    "        params['classes'] = 1\n",
    "        params['activation'] = 'identity'\n",
    "        self.model = smp.Unet(**params)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, image):\n",
    "        output = self.model(image)\n",
    "        output = output.squeeze()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "20f60adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656b78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "78581429",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x(a['image'].reshape(1,3,736,736))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cfd599be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 736, 736])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "321ab6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98dcd07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.min(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b68921ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in data['image']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
